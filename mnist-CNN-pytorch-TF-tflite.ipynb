{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From PyTorch to TensorFlow to Coral TPU\n",
    "## Introduction\n",
    "### In this article I will be showing you how to convert a PyTorch model to a TensorFlow model and run a TensorFlow model on a Coral TPU. To demonstrate this I will be testing the model son the mnist dataset which consits of handwritten digits. Also, you should know Python and some PyTorch.  This is the link for the original model: https://github.com/neel-kumar/deep-learning-mnist/blob/master/mnist-CNN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_jpg(filename):\n",
    "    return Image.open(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_jpg(a, filename):\n",
    "    ia = (a * 255).astype(np.uint8)\n",
    "    ia = np.reshape(ia, (28,28))\n",
    "    Image.fromarray(ia).save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(a, dim=(28, 28)):\n",
    "    img = np.reshape(a, dim)\n",
    "    imgplot = plt.imshow(img, cmap = \"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU found\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/37660312/how-to-run-tensorflow-on-cpu\n",
    "\n",
    "# Uncomment following to disable GPU\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model\n",
    "### TensorFlow includes an API called Keras which helps you build Neural Networks at the high level. This means that you only have to specify a few things and the rest it taken care by the computer. I chose to do this becase Keras provided me with all of the controlls I could need while not being that complicated. Alright now lets go through the model in the cell just below(If you want to see the original model go to the link at the top). Please note that this inside of a function so that if we want this model we just call the function and it creates the model. \n",
    "### Now lets look at the model. First we give it a name, which is in this case \"mnist-CNN-tf\". All the other layers are then added to the empty model to create the final model. \n",
    "- Line 2: Create the model and give it a name\n",
    "- Line 3: Conv2D\n",
    "- Line 4: Average Pool\n",
    "- Line 5: Conv2D\n",
    "- Line 6: Flattens the layer\n",
    "- Line 7: Dense is a linear layer\n",
    "- Line 8: Dense is output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = models.Sequential(name = \"mnist-CNN-tf\")\n",
    "    model.add(layers.Conv2D(8, 3, padding = 'same', activation='relu', input_shape=(28, 28, 1), name = \"layer1\"))\n",
    "    model.add(layers.AveragePooling2D((2, 2), name = \"layer2\"))\n",
    "    model.add(layers.Conv2D(13, 3, padding = 'same', activation='relu', name = \"layer3\"))\n",
    "    model.add(layers.Flatten(name = \"layer4\"))\n",
    "    model.add(layers.Dense(14*14*13, name = \"layer5\"))\n",
    "    model.add(layers.Dense(10, name = \"layer6\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist-CNN-tf\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Conv2D)              (None, 28, 28, 8)         80        \n",
      "_________________________________________________________________\n",
      "layer2 (AveragePooling2D)    (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "layer3 (Conv2D)              (None, 14, 14, 13)        949       \n",
      "_________________________________________________________________\n",
      "layer4 (Flatten)             (None, 2548)              0         \n",
      "_________________________________________________________________\n",
      "layer5 (Dense)               (None, 2548)              6494852   \n",
      "_________________________________________________________________\n",
      "layer6 (Dense)               (None, 10)                25490     \n",
      "=================================================================\n",
      "Total params: 6,521,371\n",
      "Trainable params: 6,521,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "#x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_jpg(x_test[1], \"files_0.jpg\")\n",
    "#a = x_test[0] * 255\n",
    "#ia = (a * 255).astype(np.uint8)\n",
    "#ia = np.reshape(ia, (28,28))\n",
    "# import pdb; pdb.set_trace()\n",
    "#Image.fromarray(ia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img(x_test[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-10 13:56:01.898178\n",
      "Epoch 1/20\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.1480 - accuracy: 0.9551 - val_loss: 0.0593 - val_accuracy: 0.9812\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0594 - accuracy: 0.9812 - val_loss: 0.0536 - val_accuracy: 0.9822\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0466 - accuracy: 0.9857 - val_loss: 0.0488 - val_accuracy: 0.9843\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0344 - accuracy: 0.9895 - val_loss: 0.0450 - val_accuracy: 0.9854\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0306 - accuracy: 0.9904 - val_loss: 0.0504 - val_accuracy: 0.9847\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0263 - accuracy: 0.9919 - val_loss: 0.0652 - val_accuracy: 0.9819\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 0.0524 - val_accuracy: 0.9836\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 0.0663 - val_accuracy: 0.9844\n",
      "Epoch 9/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.0678 - val_accuracy: 0.9827\n",
      "Epoch 10/20\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.0884 - val_accuracy: 0.9781\n",
      "Epoch 11/20\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0185 - accuracy: 0.9938 - val_loss: 0.0792 - val_accuracy: 0.9820\n",
      "Epoch 12/20\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.0698 - val_accuracy: 0.9833\n",
      "Epoch 13/20\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.0855 - val_accuracy: 0.9811\n",
      "Epoch 14/20\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0147 - accuracy: 0.9949 - val_loss: 0.0973 - val_accuracy: 0.9818\n",
      "Epoch 15/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.0733 - val_accuracy: 0.9861\n",
      "Epoch 16/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.0810 - val_accuracy: 0.9853\n",
      "Epoch 17/20\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.0941 - val_accuracy: 0.9829\n",
      "Epoch 18/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 0.0872 - val_accuracy: 0.9843\n",
      "Epoch 19/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.0949 - val_accuracy: 0.9832\n",
      "Epoch 20/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.1026 - val_accuracy: 0.9842\n",
      "2021-01-10 13:57:10.613145\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test, y_test))\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tflite(model):\n",
    "    # Convert the tensorflow model into a tflite file.\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    # Save the model.\n",
    "    with open('model.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
