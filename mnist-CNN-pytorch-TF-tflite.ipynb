{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From PyTorch to TensorFlow to Coral TPU\n",
    "## Introduction\n",
    "### In this article, I will show you how to convert a PyTorch model to a TensorFlow model and run a TensorFlow model on a Coral TPU. To demonstrate this, I will test the model on a dataset of handwritten digits called mnist. Also, you should know Python and some PyTorch.  This is the link for the original model in PyTorch: https://github.com/neel-kumar/deep-learning-mnist/blob/master/mnist-CNN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import tflite_runtime.interpreter as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_jpg(filename):\n",
    "    return Image.open(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_jpg(a, filename):\n",
    "    ia = (a * 255).astype(np.uint8)\n",
    "    ia = np.reshape(ia, (28,28))\n",
    "    Image.fromarray(ia).save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(a, dim=(28, 28)):\n",
    "    img = np.reshape(a, dim)\n",
    "    imgplot = plt.imshow(img, cmap = \"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU found\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/37660312/how-to-run-tensorflow-on-cpu\n",
    "\n",
    "# Uncomment following to disable GPU\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model\n",
    "### TensorFlow includes an API, called Keras, which helps you build high level Neural Networks. This means that you only have to specify a few things, and the rest it taken care by the computer. I did this because Keras provided me with all of the controls I could need while not being that complicated. Alright, now lets go through the model in the cell just below. If you want to see the original model go to the link at the top. The model is inside of a function because we can call the function to create the model (as is done in cell 7).\n",
    "### Now lets look at the model. First, we give it a name which is in this case \"mnist-CNN-tf\".Then we can add all the other layers to create the final model. This is what each of the lines do:\n",
    "- Line 2: Create the model and give it a name\n",
    "- Line 3: Conv2D\n",
    "- Line 4: Average Pool\n",
    "- Line 5: Conv2D\n",
    "- Line 6: Flattens the layer\n",
    "- Line 7: Dense is a linear layer\n",
    "- Line 8: Dense is output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = models.Sequential(name = \"mnist-CNN-tf\")\n",
    "    model.add(layers.Conv2D(8, 3, padding = 'same', activation='relu', input_shape=(28, 28, 1), name = \"layer1\"))\n",
    "    model.add(layers.AveragePooling2D((2, 2), name = \"layer2\"))\n",
    "    model.add(layers.Conv2D(13, 3, padding = 'same', activation='relu', name = \"layer3\"))\n",
    "    model.add(layers.Flatten(name = \"layer4\"))\n",
    "    model.add(layers.Dense(14*14*13, name = \"layer5\"))\n",
    "    model.add(layers.Dense(10, name = \"layer6\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist-CNN-tf\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Conv2D)              (None, 28, 28, 8)         80        \n",
      "_________________________________________________________________\n",
      "layer2 (AveragePooling2D)    (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "layer3 (Conv2D)              (None, 14, 14, 13)        949       \n",
      "_________________________________________________________________\n",
      "layer4 (Flatten)             (None, 2548)              0         \n",
      "_________________________________________________________________\n",
      "layer5 (Dense)               (None, 2548)              6494852   \n",
      "_________________________________________________________________\n",
      "layer6 (Dense)               (None, 10)                25490     \n",
      "=================================================================\n",
      "Total params: 6,521,371\n",
      "Trainable params: 6,521,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits the mnist data set\n",
    "\n",
    "mnist = tf.keras.datasets.mnista\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-10 20:02:26.339858\n",
      "Epoch 1/20\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1494 - accuracy: 0.9545 - val_loss: 0.0755 - val_accuracy: 0.9764\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0650 - accuracy: 0.9800 - val_loss: 0.0548 - val_accuracy: 0.9810\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0476 - accuracy: 0.9849 - val_loss: 0.0490 - val_accuracy: 0.9843\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0393 - accuracy: 0.9870 - val_loss: 0.0517 - val_accuracy: 0.9835\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0329 - accuracy: 0.9898 - val_loss: 0.0490 - val_accuracy: 0.9838\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0290 - accuracy: 0.9903 - val_loss: 0.0571 - val_accuracy: 0.9851\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.0826 - val_accuracy: 0.9768\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 0.0667 - val_accuracy: 0.9818\n",
      "Epoch 9/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0208 - accuracy: 0.9932 - val_loss: 0.0703 - val_accuracy: 0.9820\n",
      "Epoch 10/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0203 - accuracy: 0.9930 - val_loss: 0.0562 - val_accuracy: 0.9863\n",
      "Epoch 11/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.0654 - val_accuracy: 0.9857\n",
      "Epoch 12/20\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0774 - val_accuracy: 0.9829\n",
      "Epoch 13/20\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0721 - val_accuracy: 0.9847\n",
      "Epoch 14/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.0948 - val_accuracy: 0.9815\n",
      "Epoch 15/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.0886 - val_accuracy: 0.9818\n",
      "Epoch 16/20\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0713 - val_accuracy: 0.9865\n",
      "Epoch 17/20\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 0.0904 - val_accuracy: 0.9822\n",
      "Epoch 18/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.0759 - val_accuracy: 0.9855\n",
      "Epoch 19/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.0770 - val_accuracy: 0.9844\n",
      "Epoch 20/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.1053 - val_accuracy: 0.9828\n",
      "2021-01-10 20:03:58.026584\n"
     ]
    }
   ],
   "source": [
    "# Running the model for 20 epochs with a batch size of 64\n",
    "print(datetime.now())\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test, y_test))\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9]),\n",
       " array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], dtype=uint8))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax(axis=1), y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFlite\n",
    "### Alright, now on to TensorFlow Lite, or TFlite for short, the function below converts a TensorFlow model into a TFlite file which can be run on the TPU (Tensor Processing Unit). A TPU is just a smaller version of a GPU that is made to run Tensors. The small size of this device allows you to use AI in spaces where you can't fit a proper GPU. Since the TPU is so small it will obviously be much less powerful than a proper GPU, but is is powerful enough to significantly augment a CPU's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tflite(model, filename):\n",
    "    # Convert the tensorflow model into a tflite file.\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    # Save the model.\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "mnist_tflite_filename = \"mnist.tflite\"\n",
    "convert_to_tflite(model, mnist_tflite_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tflite_model(modelpath):\n",
    "    # Load the TFLite model and allocate tensors.\n",
    "    # Load using CPU\n",
    "    # interpreter = tf.lite.Interpreter(model_path=modelpath)\n",
    "    # Load using TPU\n",
    "    interpreter = tflite.Interpreter(model_path=modelpath,\n",
    "                                     experimental_delegates=[tflite.load_delegate('libedgetpu.so.1')])\n",
    "    interpreter.allocate_tensors()\n",
    "    return interpreter\n",
    "\n",
    "interpreter = load_tflite_model(mnist_tflite_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Model on the TPU\n",
    "### Since we created the TFlite file and loaded it onto the TPU lets run it! The function below sets up a few things before running the model on the TPU, and we can see the model is able to properly identify the image as a 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tflite_predict(interpreter, data):\n",
    "    input_data = data.reshape(1, 28, 28, 1).astype(np.float32)\n",
    "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    return interpreter.get_tensor(interpreter.get_output_details()[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tflite_predict(interpreter, x_test[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9]), 9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.argmax(1), y_test[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAOG0lEQVR4nO3db6xU9Z3H8c9H1vrfCBKRRbR/NNHGKN0QNGGzYa1tlMT/dtXExiayVCPrv0aWsA9Kog/MsqXuI/E2JaKpNE1aUh8Yt4SQqDyogkH+lFjZ6lr0BkRjikRU4LsP7qG51Tu/uc6ZmTPc7/uV3MzM+c6Z883oh3NmfnPOzxEhABPfcU03AKA/CDuQBGEHkiDsQBKEHUji7/q5Mdt89Q/0WER4rOW19uy2r7L9uu1dtpfUeS0AveVOx9ltT5L0R0nfkbRb0iuSbouIPxTWYc8O9Fgv9uxzJO2KiD9FxKeSfinpuhqvB6CH6oR9hqQ/j3q8u1r2N2wvtL3J9qYa2wJQU50v6MY6VPjCYXpEDEkakjiMB5pUZ8++W9LMUY/PkfRuvXYA9EqdsL8i6QLbX7P9FUm3Snq2O20B6LaOD+Mj4pDtRZL+R9IkSasiYkfXOgPQVR0PvXW0MT6zAz3Xkx/VADh2EHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS6Hh+dkmy/Zak/ZIOSzoUEbO70RSA7qsV9so/R8S+LrwOgB7iMB5Iom7YQ9LvbG+2vXCsJ9heaHuT7U01twWgBkdE5yvbfx8R79o+S9I6Sf8WES8Unt/5xgCMS0R4rOW19uwR8W51u1fSWklz6rwegN7pOOy2T7F92tH7kr4raXu3GgPQXXW+jZ8maa3to6/zTEQ835WuAHRdrc/sX3pjfGYHeq4nn9kBHDsIO5AEYQeSIOxAEoQdSKIbJ8LgGHb++ecX61OnTi3Wb7jhhmJ93rx5LWtHjhwprrty5cpifePGjcX6rl27ivVs2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKc9TYBXHzxxS1rixYtKq574403FuvtxtmbdOjQoWL99ddfb1l76aWXiuved999xfqnn35arDeJs96A5Ag7kARhB5Ig7EAShB1IgrADSRB2IAnOZx8Al1xySbF+zz33FOu33HJLy9rpp5/eUU9HvfPOO8X6iy++WKy/+eabLWuLFy8urrt58+Zifc6c8pwkU6ZMaVmbP39+cd3XXnutWG93rv0gYs8OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0lwPnsfPPHEE8V6u2uv1zmnfP369cX6tm3bivWlS5cW6wcPHvzSPR21YcOGYv3uu+8u1letWlWsz5o1q2Vtz549xXXPPffcYv3ss88u1t97771ivZc6Pp/d9irbe21vH7Vsiu11tt+obid3s1kA3Teew/gnJV31uWVLJK2PiAskra8eAxhgbcMeES9I+uBzi6+TtLq6v1rS9V3uC0CXdfrb+GkRMSxJETFs+6xWT7S9UNLCDrcDoEt6fiJMRAxJGpLyfkEHDIJOh9722J4uSdXt3u61BKAXOg37s5LuqO7fIem33WkHQK+0PYy3vUbSPElTbe+W9GNJj0r6le07Jb0t6Xu9bHIQnHjiiS1r7c7LXrBgQbFujzks+lftxmwff/zxlrXly5cX1z1w4ECx3ktnnnlmsT5p0qRifdmyZcX6888/37J23nnnFdediNqGPSJua1H6dpd7AdBD/FwWSIKwA0kQdiAJwg4kQdiBJLiU9DjNmzevZe2hhx4qrttuaK3d5ZpvuummYv3ll18u1nup3fDYzJkzW9aeeuqp4rrPPfdcsT55cucnW7b7b/L0008X6x9++GHH224Ke3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9nEqjScfPny41msfOnSoWL/sssuK9Ztvvrll7cILL+yop6M+/vjjYv2iiy7quL5v377iutOmTSvW62h3KelHHnmkWP/ss8+62U5fsGcHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSSYsnmcTjrppJa1Z555prjulVdeWayffPLJxfpxx5X/Ta7z37DdbwTana/epCNHjhTra9eubVm79957i+sODw931NMg6HjKZgATA2EHkiDsQBKEHUiCsANJEHYgCcIOJME4ex+cccYZxfqSJUuK9blz5xbr77//fsva22+/XVz3hBNOKNYvvfTSYn3OnDnFei+tXLmyWF+6dGnL2rF43ffx6nic3fYq23ttbx+1bJntd2xvqf7md7NZAN03nsP4JyVdNcbyn0bErOqvPHUHgMa1DXtEvCDpgz70AqCH6nxBt8j21uowv+WkW7YX2t5ke1ONbQGoqdOwPy7pG5JmSRqW9JNWT4yIoYiYHRGzO9wWgC7oKOwRsSciDkfEEUk/k9TcV7IAxqWjsNuePurhDZK2t3ougMHQdpzd9hpJ8yRNlbRH0o+rx7MkhaS3JP0wItqeAJx1nP1Y1m4O9dtvv73j196/f3+x/uCDDxbrTz75ZLFe93r+x6pW4+xtJ4mIiNvGWPzz2h0B6Ct+LgskQdiBJAg7kARhB5Ig7EASTNmc3OLFi4v1W2+9tWfbvuuuu4r1NWvW9GzbGbFnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkuJT0BLdgwYJifcWKFcX6qaeeWmv7O3bsaFmbPbt88aJPPvmk1razYspmIDnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfYJoDRt8rp164rrnnbaabW2/dFHHxXrV199dcvaxo0ba20bY2OcHUiOsANJEHYgCcIOJEHYgSQIO5AEYQeS4LrxE8A111zTslZ3HP3AgQPF+rXXXlusM5Y+ONru2W3PtL3B9k7bO2zfVy2fYnud7Teq28m9bxdAp8ZzGH9I0o8i4iJJl0u6x/Y3JS2RtD4iLpC0vnoMYEC1DXtEDEfEq9X9/ZJ2Spoh6TpJq6unrZZ0fa+aBFDfl/rMbvurkr4l6feSpkXEsDTyD4Lts1qss1DSwnptAqhr3GG3faqkX0u6PyL+Yo/5W/sviIghSUPVa3AiDNCQcQ292T5eI0H/RUT8plq8x/b0qj5d0t7etAigG9qe4uqRXfhqSR9ExP2jli+X9H5EPGp7iaQpEVGc/5c9e2faDZ/t27evZe3444+vte2hoaFivd20y+i/Vqe4jucwfq6k70vaZntLtWyppEcl/cr2nZLelvS9bjQKoDfahj0iXpLU6gP6t7vbDoBe4eeyQBKEHUiCsANJEHYgCcIOJMGlpAdAu2mRd+7cWazPmDGj421v3bq1WL/88suL9YMHD3a8bfQGl5IGkiPsQBKEHUiCsANJEHYgCcIOJEHYgSS4lPQAuOKKK4r1c845p1iv81uJBx54oFhnHH3iYM8OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzj4AHn744WK9zjj68uXLi/UNGzZ0/No4trBnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk2o6z254p6SlJZ0s6ImkoIv7b9jJJ/yrpveqpSyPiuV41OpFNmTKlWLdbTaI7Yu/evS1rjz32WEc9YeIZz49qDkn6UUS8avs0SZttr6tqP42I/+pdewC6ZTzzsw9LGq7u77e9U1LnU5AAaMSX+sxu+6uSviXp99WiRba32l5le3KLdRba3mR7U61OAdQy7rDbPlXSryXdHxF/kfS4pG9ImqWRPf9PxlovIoYiYnZEzO5CvwA6NK6w2z5eI0H/RUT8RpIiYk9EHI6II5J+JmlO79oEUFfbsHvkq+CfS9oZEStGLZ8+6mk3SNre/fYAdMt4vo2fK+n7krbZ3lItWyrpNtuzJIWktyT9sCcdJrBixYpa9dIpssPDwx31hIlnPN/GvyRprIFextSBYwi/oAOSIOxAEoQdSIKwA0kQdiAJwg4k4TqXKf7SG7P7tzEgqYgY85xo9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kES/p2zeJ+n/Rj2eWi0bRIPa26D2JdFbp7rZ23mtCn39Uc0XNm5vGtRr0w1qb4Pal0RvnepXbxzGA0kQdiCJpsM+1PD2Swa1t0HtS6K3TvWlt0Y/swPon6b37AD6hLADSTQSdttX2X7d9i7bS5rooRXbb9neZntL0/PTVXPo7bW9fdSyKbbX2X6juh1zjr2Geltm+53qvdtie35Dvc20vcH2Tts7bN9XLW/0vSv01Zf3re+f2W1PkvRHSd+RtFvSK5Jui4g/9LWRFmy/JWl2RDT+Awzb/yTpI0lPRcTF1bL/lPRBRDxa/UM5OSL+fUB6Wybpo6an8a5mK5o+eppxSddL+oEafO8Kff2L+vC+NbFnnyNpV0T8KSI+lfRLSdc10MfAi4gXJH3wucXXSVpd3V+tkf9Z+q5FbwMhIoYj4tXq/n5JR6cZb/S9K/TVF02EfYakP496vFuDNd97SPqd7c22FzbdzBimRcSwNPI/j6SzGu7n89pO491Pn5tmfGDeu06mP6+ribCPdX2sQRr/mxsR/yDpakn3VIerGJ9xTePdL2NMMz4QOp3+vK4mwr5b0sxRj8+R9G4DfYwpIt6tbvdKWqvBm4p6z9EZdKvbvQ3381eDNI33WNOMawDeuyanP28i7K9IusD212x/RdKtkp5toI8vsH1K9cWJbJ8i6bsavKmon5V0R3X/Dkm/bbCXvzEo03i3mmZcDb93jU9/HhF9/5M0XyPfyP+vpP9ooocWfX1d0mvV346me5O0RiOHdZ9p5IjoTklnSlov6Y3qdsoA9fa0pG2StmokWNMb6u0fNfLRcKukLdXf/Kbfu0JffXnf+LkskAS/oAOSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJP4fyrRx4uBgvq0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img(x_test[9])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
